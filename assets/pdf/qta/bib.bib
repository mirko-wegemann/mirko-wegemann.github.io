@article{Blei.2003a,
	title = {Latent Dirichlet Allocation},
	author = {Blei, David M. and Ng, Andrew Y. and Jordan, Michael I.},
	year = {2003},
	month = mar,
	journal = {J. Mach. Learn. Res.},
	volume = {3},
	number = {null},
	pages = {993--1022},
	issn = {1532-4435},
	abstract = {We describe latent Dirichlet allocation (LDA), a generative probabilistic model for collections of discrete data such as text corpora. LDA is a three-level hierarchical Bayesian model, in which each item of a collection is modeled as a finite mixture over an underlying set of topics. Each topic is, in turn, modeled as an infinite mixture over an underlying set of topic probabilities. In the context of text modeling, the topic probabilities provide an explicit representation of a document. We present efficient approximate inference techniques based on variational methods and an EM algorithm for empirical Bayes parameter estimation. We report results in document modeling, text classification, and collaborative filtering, comparing to a mixture of unigrams model and the probabilistic LSI model.},
	file = {C:\Users\Nutzer\Zotero\storage\7XPATSL2\Blei et al. - 2003 - Latent dirichlet allocation.pdf}
}

@misc{.ag,
  title = {An {{Introduction}} to {{Statistical Learning}}},
  journal = {An Introduction to Statistical Learning},
  url = {https://www.statlearning.com},
  urldate = {2024-09-27},
  langid = {american},
  file = {C:\Users\hp\Zotero\storage\GL8PZP5A\www.statlearning.com.html}
}

@article{Atwell.1999,
  title = {Computers Break the Language Barrier},
  author = {Atwell, Eric},
  year = {1999},
  month = oct,
  journal = {The Guardian},
  issn = {0261-3077},
  url = {https://www.theguardian.com/education/0099/oct/17/tefl.news},
  urldate = {2024-10-04},
  abstract = {The 'language machine' - a computer that can listen, understand and speak - is within reach, explains Eric Atwell},
  chapter = {Education},
  langid = {british},
  keywords = {Education,IT for schools,Online learning,Tefl},
  file = {C:\Users\hp\Zotero\storage\42VIAVEF\tefl.html}
}

@article{Baden.2020,
  title = {Hybrid {{Content Analysis}}: {{Toward}} a {{Strategy}} for the {{Theory-driven}}, {{Computer-assisted Classification}} of {{Large Text Corpora}}},
  shorttitle = {Hybrid {{Content Analysis}}},
  author = {Baden, Christian and {Kligler-Vilenchik}, Neta and Yarchi, Moran},
  year = {2020},
  month = jul,
  journal = {Communication Methods and Measures},
  publisher = {Routledge},
  issn = {1931-2458},
  url = {https://www.tandfonline.com/doi/abs/10.1080/19312458.2020.1803247},
  urldate = {2024-06-02},
  abstract = {Given the scale of digital communication, researchers face a painful trade-off between powerful, scalable computational strategies, and the theoretical sensitivity offered by small-scale manual ana...},
  copyright = {{\copyright} 2020 Taylor \& Francis Group, LLC},
  langid = {english},
  keywords = {No DOI found},
  file = {C:\Users\hp\Zotero\storage\4TRFYS8E\19312458.2020.html}
}

@article{Bauer.2017,
  title = {Is the {{Left-Right Scale}} a {{Valid Measure}} of {{Ideology}}?},
  author = {Bauer, Paul C. and Barber{\'a}, Pablo and Ackermann, Kathrin and Venetz, Aaron},
  year = {2017},
  month = sep,
  journal = {Political Behavior},
  volume = {39},
  number = {3},
  pages = {553--583},
  issn = {1573-6687},
  doi = {10.1007/s11109-016-9368-2},
  url = {https://doi.org/10.1007/s11109-016-9368-2},
  urldate = {2024-04-25},
  abstract = {In order to measure ideology, political scientists heavily rely on the so-called left-right scale. Left and right are, however, abstract political concepts and may trigger different associations among respondents. If these associations vary systematically with other variables this may induce bias in the empirical study of ideology. We illustrate this problem using a unique survey that asked respondents open-ended questions regarding the meanings they attribute to the concepts ``left'' and ``right''. We assess and categorize this textual data using topic modeling techniques. Our analysis shows that variation in respondents' associations is systematically related to their self-placement on the left-right scale and also to variables such as education and respondents' cultural background (East vs. West Germany). Our findings indicate that the interpersonal comparability of the left-right scale across individuals is impaired. More generally, our study suggests that we need more research on how respondents interpret various abstract concepts that we regularly use in survey questions.},
  langid = {english},
  keywords = {Ideology,Interpersonal comparability,Left,Left-right scale,Measurement equivalence,Right,Survey measurement},
  file = {C:\Users\hp\Zotero\storage\HKV92B66\Bauer et al. - 2017 - Is the Left-Right Scale a Valid Measure of Ideolog.pdf}
}

@article{Bauer.2017a,
  title = {Is the {{Left-Right Scale}} a {{Valid Measure}} of {{Ideology}}?},
  author = {Bauer, Paul C. and Barber{\'a}, Pablo and Ackermann, Kathrin and Venetz, Aaron},
  year = {2017},
  month = sep,
  journal = {Political Behavior},
  volume = {39},
  number = {3},
  pages = {553--583},
  issn = {1573-6687},
  doi = {10.1007/s11109-016-9368-2},
  url = {https://doi.org/10.1007/s11109-016-9368-2},
  urldate = {2024-09-19},
  abstract = {In order to measure ideology, political scientists heavily rely on the so-called left-right scale. Left and right are, however, abstract political concepts and may trigger different associations among respondents. If these associations vary systematically with other variables this may induce bias in the empirical study of ideology. We illustrate this problem using a unique survey that asked respondents open-ended questions regarding the meanings they attribute to the concepts ``left'' and ``right''. We assess and categorize this textual data using topic modeling techniques. Our analysis shows that variation in respondents' associations is systematically related to their self-placement on the left-right scale and also to variables such as education and respondents' cultural background (East vs. West Germany). Our findings indicate that the interpersonal comparability of the left-right scale across individuals is impaired. More generally, our study suggests that we need more research on how respondents interpret various abstract concepts that we regularly use in survey questions.},
  langid = {english},
  keywords = {Ideology,Interpersonal comparability,Left,Left-right scale,Measurement equivalence,Right,Survey measurement},
  file = {C:\Users\hp\Zotero\storage\MPF94MJB\Bauer et al. - 2017 - Is the Left-Right Scale a Valid Measure of Ideolog.pdf}
}

@misc{Baumann.2016,
  title = {Where {{Is My Party}}? {{Introducing New Data Sets}} on {{Ideological Cohesion}} and {{Ambiguity}} of {{Party Positions}} in {{Media Coverage}}},
  author = {Baumann, Markus and Gross, Martin},
  year = {2016},
  url = {http://www.mzes.uni-mannheim.de/d7/en/publications/report/where-is-my-party-introducing-new-data-sets-on-ideological-cohesion-and-ambiguity-of-party-positions-in-media-coverage},
  urldate = {2024-09-30},
  file = {C:\Users\hp\Zotero\storage\UGBJIE9C\where-is-my-party-introducing-new-data-sets-on-ideological-cohesion-and-ambiguity-of-party-posi.html}
}

@misc{Benoit.2009,
  title = {Introduction to Quantitative Text Analysis},
  author = {Benoit, Kenneth},
  year = {2009},
  address = {ECPR Summer School}
}

@incollection{Benoit.2020,
  title = {Text as Data: An Overview.},
  booktitle = {The {{SAGE Handbook}} of {{Research Methods}} in {{Political Science}} and {{International Relations}}},
  author = {Benoit, Kenneth},
  editor = {Curini, Luigi and Franzese, Robert},
  year = {2020},
  publisher = {SAGE Publications Ltd},
  address = {1 Oliver's Yard,~55 City Road~London~EC1Y 1SP},
  doi = {10.4135/9781526486387},
  url = {https://sk.sagepub.com/reference/the-sage-handbook-of-research-methods-in-political-science-and-ir},
  urldate = {2024-05-13},
  isbn = {978-1-5264-5993-0 978-1-5264-8638-7}
}

@article{Bischof.2023,
  title = {Place-{{Based Campaigning}}: {{The Political Impact}} of {{Real Grassroots Mobilization}}},
  shorttitle = {Place-{{Based Campaigning}}},
  author = {Bischof, Daniel and Kurer, Thomas},
  year = {2023},
  month = jul,
  journal = {The Journal of Politics},
  volume = {85},
  number = {3},
  pages = {984--1002},
  publisher = {The University of Chicago Press},
  issn = {0022-3816},
  doi = {10.1086/723985},
  url = {https://www.journals.uchicago.edu/doi/full/10.1086/723985},
  urldate = {2024-05-20},
  abstract = {Generations of research have incrementally identified the circumstances under which electoral campaigns matter. Direct interpersonal contact within local networks is commonly seen as conducive to campaign impact, but empirical evidence is scarce because of demanding data requirements. We advance the literature by studying the Movimento Cinque Stelle (M5S), an important challenger party in Italy, which followed the unusual practice of coordinating political activities on a public online platform. We web scraped the entire history of the movement's more than 1,000 local branches with over 200,000 geocoded political activities, to study the effect and mechanisms of their no campaign in the 2016 constitutional referendum. Relying on regression, matching, and instrumental variable models, we demonstrate that local M5S mobilization had substantial campaign effects. Our results have important implications, as they highlight the effectiveness of locally rooted campaigns and the particular potency of place-based political mobilization.},
  keywords = {comparative politics,electoral campaigns,European politics,political behavior,political parties and interest groups,public opinion,voting behavior},
  file = {C:\Users\hp\Zotero\storage\9VDWHDCE\Bischof and Kurer - 2023 - Place-Based Campaigning The Political Impact of R.pdf}
}

@article{Bonikowski.2022,
  title = {From {{Ends}} to {{Means}}: {{The Promise}} of {{Computational Text Analysis}} for {{Theoretically Driven Sociological Research}}},
  shorttitle = {From {{Ends}} to {{Means}}},
  author = {Bonikowski, Bart and Nelson, Laura K.},
  year = {2022},
  month = nov,
  journal = {Sociological Methods \& Research},
  volume = {51},
  number = {4},
  pages = {1469--1483},
  issn = {0049-1241, 1552-8294},
  doi = {10.1177/00491241221123088},
  url = {http://journals.sagepub.com/doi/10.1177/00491241221123088},
  urldate = {2024-04-25},
  abstract = {As the field of computational text analysis within the social sciences is maturing, computational methods are no longer seen as ends in themselves, but rather as means toward answering theoretically motivated research questions. The objective of this special issue is to showcase such research: the use of novel computational methods in the service of advancing substantive scientific knowledge. In presenting the contributions to the issue, we discuss several insights that emerge from this work, which hold relevance not only for current and aspiring practitioners of computational text analysis, but also for its skeptics. These concern the central role of theory in designing and executing computational research, the selection of appropriate techniques from a rapidly growing methodological toolkit, the benefits---and risks---of methodological bricolage, and the necessity of validating all aspects of the research process. The result is a set of broad considerations concerning the effective application of computational methods to substantive questions, illustrated by eight exemplary empirical studies.},
  langid = {english},
  file = {C:\Users\hp\Zotero\storage\G85FK8LY\Bonikowski and Nelson - 2022 - From Ends to Means The Promise of Computational T.pdf}
}

@article{Boussalis.2021,
  title = {Gender, {{Candidate Emotional Expression}}, and {{Voter Reactions During Televised Debates}}},
  author = {Boussalis, Constantine and Coan, Travis G. and Holman, Mirya R. and M{\"u}ller, Stefan},
  year = {2021},
  month = nov,
  journal = {American Political Science Review},
  volume = {115},
  number = {4},
  pages = {1242--1257},
  issn = {0003-0554, 1537-5943},
  doi = {10.1017/S0003055421000666},
  url = {https://www.cambridge.org/core/journals/american-political-science-review/article/gender-candidate-emotional-expression-and-voter-reactions-during-televised-debates/B259E3277178F68F52CCEADF5AE0CD40},
  urldate = {2024-05-16},
  abstract = {Voters evaluate politicians not just by what they say, but also how they say it, via facial displays of emotions and vocal pitch. Candidate characteristics can shape how leaders use---and how voters react to---nonverbal cues. Drawing on role congruity expectations, we study how the use of and reactions to facial, vocal, and textual communication in political debates varies by candidate gender. Relying on full-length videos of four German federal election debates (2005--2017) and a minor party debate, we use video, audio, and text data to measure candidate facial displays of emotion, vocal pitch, and speech sentiment. Consistent with our expectations, Angela Merkel expresses less anger than her male opponents, but she is just as emotive in other respects. Combining these measures of emotional expression with continuous responses recorded by live audiences, we find that voters punish Merkel for anger displays and reward her happiness and general emotional displays.},
  langid = {english},
  file = {C:\Users\hp\Zotero\storage\UBW3TR9J\Boussalis et al. - 2021 - Gender, Candidate Emotional Expression, and Voter .pdf}
}

@article{Cantu.2019,
  title = {The {{Fingerprints}} of {{Fraud}}: {{Evidence}} from {{Mexico}}'s 1988 {{Presidential Election}}},
  shorttitle = {The {{Fingerprints}} of {{Fraud}}},
  author = {Cant{\'u}, Francisco},
  year = {2019},
  month = aug,
  journal = {American Political Science Review},
  volume = {113},
  number = {3},
  pages = {710--726},
  issn = {0003-0554, 1537-5943},
  doi = {10.1017/S0003055419000285},
  url = {https://www.cambridge.org/core/journals/american-political-science-review/article/fingerprints-of-fraud-evidence-from-mexicos-1988-presidential-election/8F3C1BCA4C53FE85EA48E51321E339E9},
  urldate = {2024-05-16},
  abstract = {This paper investigates the opportunities for non-democratic regimes to rely on fraud by documenting the alteration of vote tallies during the 1988 presidential election in Mexico. In particular, I study how the alteration of vote returns came after an electoral reform that centralized the vote-counting process. Using an original image database of the vote-tally sheets for that election and applying Convolutional Neural Networks (CNN) to analyze the sheets, I find evidence of blatant alterations in about a third of the tallies in the country. This empirical analysis shows that altered tallies were more prevalent in polling stations where the opposition was not present and in states controlled by governors with grassroots experience of managing the electoral operation. This research has implications for understanding the ways in which autocrats control elections as well as for introducing a new methodology to audit the integrity of vote tallies.},
  langid = {english},
  file = {C:\Users\hp\Zotero\storage\5JVYA6BM\Cantú - 2019 - The Fingerprints of Fraud Evidence from Mexico’s .pdf}
}

@misc{ChunTing-Ho.2021,
  title = {Introduction to {{Computational Text Analysis}} and {{Social Media Research}} Using {{R}}},
  author = {{Chun Ting-Ho}, Justin},
  year = {2021},
  journal = {School of Research},
  url = {https://www.sciencespo.fr/ecole-recherche/en/news/introduction-computational-text-analysis-and-social-media-research-using-r},
  urldate = {2024-10-05},
  abstract = {Free of charge - open to all masters and doctoral students. No prior knowledge of R neededJustin Chun-ting HO, Postdoctoral Researcher at Sciences Po\&nbsp;What is Computational Text Analysis ?\&nbsp;{$>$}Computational text analysis (also called Quantitative Text Analysis, Automated Content Analysis, Text Mining, Text as Data etc.) draws on techniques},
  langid = {english},
  file = {C:\Users\hp\Zotero\storage\GWCRPXRT\introduction-computational-text-analysis-and-social-media-research-using-r.html}
}

@misc{Denny.2017,
  type = {{{SSRN Scholarly Paper}}},
  title = {Text {{Preprocessing}} for {{Unsupervised Learning}}: {{Why It Matters}}, {{When It Misleads}}, and {{What}} to {{Do}} about {{It}}},
  shorttitle = {Text {{Preprocessing}} for {{Unsupervised Learning}}},
  author = {Denny, Matthew and Spirling, Arthur},
  year = {2017},
  month = sep,
  number = {2849145},
  address = {Rochester, NY},
  doi = {10.2139/ssrn.2849145},
  url = {https://papers.ssrn.com/abstract=2849145},
  urldate = {2024-09-05},
  abstract = {Despite the popularity of unsupervised techniques for political science text-as-data research, the importance and implications of preprocessing decisions in this domain have received scant systematic attention.  Yet, as we show, such decisions have profound effects on the results of real models for real data. We argue that substantive theory is typically too vague to be of use for feature selection, and that the supervised literature is not necessarily a helpful source of advice.  To aid researchers working in unsupervised settings, we introduce a statistical procedure and software that examines the sensitivity of findings under alternate preprocessing regimes.  This approach complements a researcher's substantive understanding of a problem by providing a characterization of the variability changes in preprocessing choices may induce when analyzing a particular dataset.  In making scholars aware of the degree to which their results are likely to be sensitive to their preprocessing decisions, it aids replication efforts.},
  langid = {english},
  keywords = {forking paths,preprocessing,text-as-data},
  file = {C:\Users\hp\Zotero\storage\YAVW96WS\Denny and Spirling - 2017 - Text Preprocessing for Unsupervised Learning Why .pdf}
}

@misc{Ellis.2024,
  title = {Einf{\"u}hrung in {{R}}},
  author = {Ellis, Andrew and Mayer, Boris},
  year = {2024},
  url = {https://methodenlehre.github.io/einfuehrung-in-R/Einf\%C3\%BChrung-in-R.pdf},
  file = {C:\Users\hp\Zotero\storage\3JDHSVDE\Einführung-in-R.pdf}
}

@article{Gessler.2022,
  title = {How the {{Refugee Crisis}} and {{Radical Right Parties Shape Party Competition}} on {{Immigration}}},
  author = {Gessler, Theresa and Hunger, Sophia},
  year = {2022},
  journal = {Political Science Research and Methods},
  volume = {10},
  pages = {524--544},
  doi = {10.1017/psrm.2021.64},
  abstract = {While the structure of party competition evolves slowly, crisis-like events can induce short-term change to the political agenda. This may be facilitated by challenger parties who might benefit from increased attention to issues they own. We study the dynamic of such shifts through mainstream parties' response to the 2015 refugee crisis, which strongly affected public debate and election outcomes across Europe. Specifically, we analyse how parties changed their issue emphasis and positions regarding immigration before, during, and after the refugee crisis. Our study is based on a corpus of 120,000 press releases between 2013 and 2017 from Austria, Germany, and Switzerland. We identify immigration-related press releases using a novel dictionary and estimate party positions. The resulting monthly salience and positions measures allow for studying changes in close time-intervals, providing crucial detail for disentangling the impact of the crisis itself and the contribution of right-wing parties. While we provide evidence that attention to immigration increased drastically for all parties during the crisis, radical right parties drove the attention of mainstream parties. However, the attention of mainstream parties to immigration decreased toward the end of the refugee crisis and there is limited evidence of parties accommodating the positions of the radical right.},
  langid = {english},
  file = {C:\Users\hp\Zotero\storage\I6YJ66B3\Gessler and Hunger - How the refugee crisis and radical right parties s.pdf}
}

@article{Grimmer.2013a,
  title = {Text as {{Data}}: {{The Promise}} and {{Pitfalls}} of {{Automatic Content Analysis Methods}} for {{Political Texts}}},
  shorttitle = {Text as {{Data}}},
  author = {Grimmer, Justin and Stewart, Brandon M.},
  year = {2013},
  month = jul,
  journal = {Political Analysis},
  volume = {21},
  number = {3},
  pages = {267--297},
  publisher = {Cambridge University Press},
  issn = {1047-1987, 1476-4989},
  doi = {10.1093/pan/mps028},
  url = {https://www.cambridge.org/core/journals/political-analysis/article/text-as-datathe-promise-and-pitfalls-of-automatic-content-analysis-methods-for-politicaltexts/F7AAC8B2909441603FEB25C156448F20},
  urldate = {2023-11-28},
  abstract = {Politics and political conflict often occur in the written and spoken word. Scholars have long recognized this, but the massive costs of analyzing even moderately sized collections of texts have hindered their use in political science research. Here lies the promise of automated text analysis: it substantially reduces the costs of analyzing large collections of text. We provide a guide to this exciting new area of research and show how, in many instances, the methods have already obtained part of their promise. But there are pitfalls to using automated methods---they are no substitute for careful thought and close reading and require extensive and problem-specific validation. We survey a wide range of new methods, provide guidance on how to validate the output of the models, and clarify misconceptions and errors in the literature. To conclude, we argue that for automated text methods to become a standard tool for political scientists, methodologists must contribute new methods and new methods of validation.},
  langid = {english},
  file = {C:\Users\hp\Zotero\storage\4BIGX9RA\Grimmer und Stewart - 2013 - Text as Data The Promise and Pitfalls of Automati.pdf}
}

@misc{Harrison.2022,
  title = {{{RSelenium}}: {{R Bindings}} for '{{Selenium WebDriver}}'},
  shorttitle = {{{RSelenium}}},
  author = {Harrison, John and Ju Yeong, Kim},
  year = {2022},
  month = sep,
  url = {https://cran.r-project.org/web/packages/RSelenium/index.html},
  urldate = {2024-09-06},
  abstract = {Provides a set of R bindings for the 'Selenium 2.0 WebDriver' (see {$<$}https://www.selenium.dev/documentation/{$>$} for more information) using the 'JsonWireProtocol' (see {$<$}https://github.com/SeleniumHQ/selenium/wiki/JsonWireProtocol{$>$} for more information). 'Selenium 2.0 WebDriver' allows driving a web browser natively as a user would either locally or on a remote machine using the Selenium server it marks a leap forward in terms of web browser automation. Selenium automates web browsers (commonly referred to as browsers). Using RSelenium you can automate browsers locally or remotely.},
  copyright = {AGPL-3},
  keywords = {WebTechnologies}
}

@book{Hvitfeldt.2022,
  title = {Supervised {{Machine Learning}} for {{Text Analysis}} in {{R}}},
  author = {Hvitfeldt, Emil and Silge, Julia},
  year = {2022},
  publisher = {CRC Press},
  url = {https://smltar.com/},
  urldate = {2024-09-27},
  abstract = {Supervised Machine Learning for Text Analysis in R},
  file = {C:\Users\hp\Zotero\storage\EEEX5TFI\smltar.com.html}
}

@book{James.2021,
  title = {An {{Introduction}} to {{Statistical Learning}}},
  author = {James, Gareth and Witten, Daniela and Hastie, Trevor and Tibshirani},
  year = {2021},
  url = {https://www.statlearning.com},
  urldate = {2024-09-19},
  langid = {american},
  file = {C:\Users\hp\Zotero\storage\IJ8JY39P\www.statlearning.com.html}
}

@misc{Jankin.2024,
  title = {United {{Nations General Debate Corpus}} 1946-2023},
  author = {Jankin, Slava and Baturo, Alexander and Dasandi, Niheer},
  year = {2024},
  month = aug,
  publisher = {Harvard Dataverse},
  doi = {10.7910/DVN/0TJX8Y},
  url = {https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/0TJX8Y},
  urldate = {2024-09-30},
  abstract = {Every year since 1946, the General Debate has taken place at the beginning of the UN General Assembly session. Representatives from all UN member states deliver an address, discussing the issues they consider most important in global politics, revealing their governments' positions, and seeking to persuade other states of their perspectives. The annual UN General Debate statements provide invaluable information for scholars of international relations -- comparable globally and over time. However, these texts are stored as poor quality images without relevant metadata, preventing researchers from applying data science methods. This paper introduces the complete UN General Debate Corpus (UNGDC). Building on a previous incomplete release of UNGDC, we have extended the corpus to cover the entire 1946-present period, included additional data on all speakers, and provided advanced search and data visualisation tools on a new website. The complete corpus contains over 10,000 speeches from 202 countries, including historical countries -- making it the most comprehensive, unique, and accessible collection of global political speeches.},
  copyright = {http://creativecommons.org/publicdomain/zero/1.0},
  langid = {english},
  keywords = {Arts and Humanities,Computer and Information Science,Social Sciences},
  file = {C:\Users\hp\Zotero\storage\I342U69K\dataset.html}
}

@book{Jockers.2020,
  title = {Text {{Analysis}} with {{R}}: {{For Students}} of {{Literature}}},
  shorttitle = {Text {{Analysis}} with {{R}}},
  author = {Jockers, Matthew Lee and Thalken, Rosamond},
  year = {2020},
  series = {Quantitative Methods in the Humanities and Social Sciences},
  edition = {2nd edition},
  publisher = {Springer},
  address = {Cham Heidelberg New York Dordrecht London},
  isbn = {978-3-030-39643-5 978-3-030-39642-8},
  langid = {english}
}

@misc{Klein.2023,
  title = {A.{{I}}. {{Could Solve Some}} of {{Humanity}}'s {{Hardest Problems}}. {{It Already Has}}.},
  author = {Klein, Ezra},
  url = {https://www.youtube.com/watch?v=U8CmAu68z5c},
  collaborator = {Hassabis, Demis}
}

@article{Kozlowski.2019,
  title = {The {{Geometry}} of {{Culture}}: {{Analyzing}} the {{Meanings}} of {{Class}} through {{Word Embeddings}}},
  shorttitle = {The {{Geometry}} of {{Culture}}},
  author = {Kozlowski, Austin C. and Taddy, Matt and Evans, James A.},
  year = {2019},
  month = oct,
  journal = {American Sociological Review},
  volume = {84},
  number = {5},
  pages = {905--949},
  publisher = {SAGE Publications Inc},
  issn = {0003-1224},
  doi = {10.1177/0003122419877135},
  url = {https://doi.org/10.1177/0003122419877135},
  urldate = {2024-05-28},
  abstract = {We argue word embedding models are a useful tool for the study of culture using a historical analysis of shared understandings of social class as an empirical case. Word embeddings represent semantic relations between words as relationships between vectors in a high-dimensional space, specifying a relational model of meaning consistent with contemporary theories of culture. Dimensions induced by word differences (rich -- poor) in these spaces correspond to dimensions of cultural meaning, and the projection of words onto these dimensions reflects widely shared associations, which we validate with surveys. Analyzing text from millions of books published over 100 years, we show that the markers of class continuously shifted amidst the economic transformations of the twentieth century, yet the basic cultural dimensions of class remained remarkably stable. The notable exception is education, which became tightly linked to affluence independent of its association with cultivated taste.},
  langid = {english},
  file = {C:\Users\hp\Zotero\storage\V7C74ETT\Kozlowski et al. - 2019 - The Geometry of Culture Analyzing the Meanings of.pdf}
}

@book{Krippendorff.2018,
  title = {Content {{Analysis}}: {{An Introduction}} to Its {{Methodology}}},
  shorttitle = {Content Analysis},
  author = {Krippendorff, Klaus},
  year = {2018},
  edition = {Fourth Edition},
  publisher = {SAGE},
  address = {Los Angeles},
  isbn = {978-1-5063-9566-1},
  langid = {english},
  lccn = {P93 .K74 2018},
  keywords = {Content analysis (Communication)},
  file = {C:\Users\hp\Zotero\storage\8XINKNRF\Krippendorff - 2018 - Content analysis an introduction to its methodolo.pdf}
}

@book{Labatut.2023,
  title = {The {{Maniac}}},
  author = {Labatut, Benjam{\'i}n},
  year = {2023},
  publisher = {Penguin Press},
  address = {New York},
  abstract = {"A story centered around one of the great geniuses of the modern age, the Hungarian polymath John von Neumann, tracing the uncanny circuit of his mind deep into our own time's most haunting dilemmas"--},
  isbn = {978-0-593-65448-4},
  lccn = {PR9309.9.L33},
  keywords = {Biographical fiction,Fiction,Novels,Von Neumann John}
}

@misc{Lehmann.2024a,
  title = {Manifesto {{Project Dataset}}},
  author = {Lehmann, Pola and Franzmann, Simon and {Al-Gaddooa}, Denise and Burst, Tobias and Ivanusch, Christoph and Regel, Sven and Riethm{\"u}ller, Felicia and Volkens, Andrea and We{\ss}els, Bernhard and Zehnter, Lisa and {Wissenschaftszentrum Berlin F{\"u}r Sozialforschung (WZB)} and {Institut F{\"u}r Demokratieforschung G{\"o}ttingen (IfDem)}},
  year = {2024},
  publisher = {Manifesto Project},
  doi = {10.25522/MANIFESTO.MPDS.2024A},
  url = {https://manifesto-project.wzb.eu/doi/manifesto.mpds.2024a},
  urldate = {2024-09-30},
  abstract = {The Manifesto Project Dataset provides the scientific community with parties' policy positions derived from a content analysis of parties' electoral manifestos. It covers over 1.000 parties from 1945 until today in over 50 countries on five continents.  The content analysis aims to discover party and presidential stances by quantifying their statements and messages to their electorate. A unified classification scheme with an accompanying set of rules was developed to make such statements comparable. Analysing manifestos allows for measurement of party and presidents' policy positions across countries and elections within a common framework. Manifestos are understood to be parties' only and presidential candidates' main authoritative policy statements and, therefore, as indicators of the parties' policy preferences at a given point in time.  The Manifesto Project Data Collection was originally created by the Manifesto Research Group (MRG) in the late 1970s and the 1980s. The work was continued under the name Comparative Manifestos Project (CMP) at the WZB Berlin Social Science Center in the 1990s and 2000s. Since 2009 the Manifesto Research on Political Representation (MARPOR) project updates and extends the dataset. It is funded by the German Research Foundation (DFG) and is still located at the WZB Berlin Social Science Center. In November 2022 the Manifesto Project has found a second home at the IfDem -- Institute for Democracy Research G{\"o}ttingen (University of G{\"o}ttingen).},
  langid = {english},
  keywords = {comparative political science,content analysis,party,party politics,political program}
}

@book{Lennert.,
  title = {Text {{Mining}} for {{Social Scientists}}},
  author = {Lennert, Felix},
  url = {https://bookdown.org/f\_lennert/text-mining-book/},
  urldate = {2024-10-04},
  abstract = {This book is supposed to introduce the reader (i.e., you) to a fundamental technique for computational social science research: the quantitative analysis of text.},
  file = {C:\Users\hp\Zotero\storage\ITX4BIRA\text-mining-book.html}
}

@misc{Marble.2016,
  title = {Web-{{Scraping}} with {{R}}},
  author = {Marble, William},
  year = {2016},
  url = {https://williammarble.co/files/webscraping\_tutorial/webscraping\_tutorial.pdf}
}

@book{Munzert.2015,
  title = {Automated {{Data Collection}} with {{R}}: {{A Practical Guide}} to {{Web Scraping}} and {{Text Mining}}},
  shorttitle = {Automated Data Collection with {{R}}},
  author = {Munzert, Simon},
  year = {2015},
  edition = {1st ed.},
  publisher = {Wiley},
  address = {Chichester, England},
  abstract = {"This book provides a unified framework of web scraping and information extraction from text data with R for the social sciences"-- Provided by publisher.},
  collaborator = {Munzert, Simon},
  isbn = {978-1-118-83480-0},
  langid = {english},
  keywords = {Automatic data collection systems,Data mining,Data processing,R (Computer program language),Research,Social sciences},
  file = {C:\Users\hp\Zotero\storage\YEQQFJ5T\Munzert - 2015 - Automated data collection with R a practical guid.pdf}
}

@misc{OpenKnowledgeFoundationDeutschlande.V..2024,
  title = {{{kleineAnfragen}}},
  author = {{Open Knowledge Foundation Deutschland e.V.}},
  year = {2024},
  journal = {kleineAnfragen},
  url = {https://kleineanfragen.de/},
  urldate = {2024-10-04},
  abstract = {kleineAnfragen sammelt kleine und gro{\ss}e Anfragen von den Landesparlamenten und macht diese durchsuch- und verlinkbar},
  file = {C:\Users\hp\Zotero\storage\86QTYX6Q\kleineanfragen.de.html}
}

@article{Pauwels.2011,
  title = {Measuring {{Populism}}: {{A Quantitative Text Analysis}} of {{Party Literature}} in {{Belgium}}},
  shorttitle = {Measuring {{Populism}}},
  author = {Pauwels, Teun},
  year = {2011},
  month = feb,
  journal = {Journal of Elections, Public Opinion and Parties},
  volume = {21},
  number = {1},
  pages = {97--119},
  publisher = {Routledge},
  issn = {1745-7289},
  doi = {10.1080/17457289.2011.539483},
  url = {https://www.tandfonline.com/doi/full/10.1080/17457289.2011.539483},
  urldate = {2024-04-25},
  file = {C:\Users\hp\Zotero\storage\IBJW32T5\Pauwels - 2011 - Measuring Populism A Quantitative Text Analysis o.pdf}
}

@misc{Rauh.2020a,
  title = {The {{ParlSpeech V2}} Data Set: {{Full-text}} Corpora of 6.3 Million Parliamentary Speeches in the Key Legislative Chambers of Nine Representative Democracies},
  shorttitle = {The {{ParlSpeech V2}} Data Set},
  author = {Rauh, Christian and Schwalbach, Jan},
  year = {2020},
  month = mar,
  publisher = {Harvard Dataverse},
  doi = {10.7910/DVN/L4OAKN},
  url = {https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/L4OAKN},
  urldate = {2024-09-27},
  abstract = {ParlSpeech V2 contains complete full-text vectors of more than 6.3 million parliamentary speeches in the key legislative chambers of Austria, the Czech Republic, Germany, Denmark, the Netherlands, New Zealand, Spain, Sweden, and the United Kingdom, covering periods between 21 and 32 years. Meta-data include information on date, speaker, party, and partially agenda item under which a speech was held. The accompanying release note provides a more detailed guide to the data.},
  copyright = {http://creativecommons.org/publicdomain/zero/1.0},
  langid = {english},
  keywords = {Computer and Information Science,Social Sciences},
  file = {C:\Users\hp\Zotero\storage\LW332Z9Z\dataset.html}
}

@misc{Rauh.2020b,
  title = {The {{ParlSpeech V2}} Data Set: {{Full-text}} Corpora of 6.3 Million Parliamentary Speeches in the Key Legislative Chambers of Nine Representative Democracies},
  shorttitle = {The {{ParlSpeech V2}} Data Set},
  author = {Rauh, Christian and Schwalbach, Jan},
  year = {2020},
  month = mar,
  publisher = {Harvard Dataverse},
  doi = {10.7910/DVN/L4OAKN},
  url = {https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/L4OAKN},
  urldate = {2024-09-30},
  abstract = {ParlSpeech V2 contains complete full-text vectors of more than 6.3 million parliamentary speeches in the key legislative chambers of Austria, the Czech Republic, Germany, Denmark, the Netherlands, New Zealand, Spain, Sweden, and the United Kingdom, covering periods between 21 and 32 years. Meta-data include information on date, speaker, party, and partially agenda item under which a speech was held. The accompanying release note provides a more detailed guide to the data.},
  copyright = {http://creativecommons.org/publicdomain/zero/1.0},
  langid = {english},
  keywords = {Computer and Information Science,Social Sciences}
}

@article{Roberts.2019a,
  title = {Stm: {{An R Package}} for {{Structural Topic Models}}},
  shorttitle = {Stm},
  author = {Roberts, Margaret E. and Stewart, Brandon M. and Tingley, Dustin},
  year = {2019},
  month = oct,
  journal = {Journal of Statistical Software},
  volume = {91},
  pages = {1--40},
  issn = {1548-7660},
  doi = {10.18637/jss.v091.i02},
  url = {https://doi.org/10.18637/jss.v091.i02},
  urldate = {2024-04-30},
  abstract = {This paper demonstrates how to use the R package stm for structural topic modeling. The structural topic model allows researchers to flexibly estimate a topic model that includes document-level metadata. Estimation is accomplished through a fast variational approximation. The stm package provides many useful features, including rich ways to explore topics, estimate uncertainty, and visualize quantities of interest.},
  copyright = {Copyright (c) 2019 Margaret E. Roberts, Brandon M. Stewart, Dustin Tingley},
  langid = {english},
  keywords = {LDA,R,stm,structural topic model,text analysis},
  file = {C:\Users\hp\Zotero\storage\D6LUEI5E\Roberts et al. - 2019 - stm An R Package for Structural Topic Models.pdf}
}

@book{Robinson.,
  title = {Welcome to {{Text Mining}} with {{R}} {\textbar} {{Text Mining}} with {{R}}},
  author = {Robinson, Julia Silge {and} David},
  url = {https://www.tidytextmining.com/},
  urldate = {2024-10-04},
  abstract = {A guide to text analysis within the tidy data framework, using the tidytext package and other tidy tools},
  langid = {english},
  file = {C:\Users\hp\Zotero\storage\JPKN8JFY\www.tidytextmining.com.html}
}

@article{Rodman.2020,
  title = {A {{Timely Intervention}}: {{Tracking}} the {{Changing Meanings}} of {{Political Concepts}} with {{Word Vectors}}},
  shorttitle = {A {{Timely Intervention}}},
  author = {Rodman, Emma},
  year = {2020},
  month = jan,
  journal = {Political Analysis},
  volume = {28},
  number = {1},
  pages = {87--111},
  issn = {1047-1987, 1476-4989},
  doi = {10.1017/pan.2019.23},
  url = {https://www.cambridge.org/core/journals/political-analysis/article/abs/timely-intervention-tracking-the-changing-meanings-of-political-concepts-with-word-vectors/DDF3B5833A12E673EEE24FBD9798679E},
  urldate = {2024-05-28},
  abstract = {Word vectorization is an emerging text-as-data method that shows great promise for automating the analysis of semantics---here, the cultural meanings of words---in large volumes of text. Yet successes with this method have largely been confined to massive corpora where the meanings of words are presumed to be fixed. In political science applications, however, many corpora are comparatively small and many interesting questions hinge on the recognition that meaning changes over time. Together, these two facts raise vexing methodological challenges. Can word vectors trace the changing cultural meanings of words in typical small corpora use cases? I test four time-sensitive implementations of word vectors (word2vec) against a gold standard developed from a modest data set of 161 years of newspaper coverage. I find that one implementation method clearly outperforms the others in matching human assessments of how public dialogues around equality in America have changed over time. In addition, I suggest best practices for using word2vec to study small corpora for time series questions, including bootstrap resampling of documents and pretraining of vectors. I close by showing that word2vec allows granular analysis of the changing meaning of words, an advance over other common text-as-data methods for semantic research questions.},
  langid = {english},
  keywords = {analysis of political speech,automated content analysis,statistical analysis of texts,time series},
  file = {C:\Users\hp\Zotero\storage\8RIZ3AVA\Rodman - 2020 - A Timely Intervention Tracking the Changing Meani.pdf}
}

@article{Rodriguez.2021,
  title = {Word {{Embeddings}}: {{What}} Works, What Doesn't, and How to Tell the Difference for Applied Research},
  author = {Rodriguez, Pedro and Spirling, Arthur},
  year = {2021},
  month = jan,
  journal = {The Journal of Politics},
  issn = {0022-3816},
  doi = {10.1086/715162},
  abstract = {The Journal of Politics 0.0},
  file = {C:\Users\hp\Zotero\storage\WKFEDEPP\Rodriguez and Spirling - 2021 - Word Embeddings What works, what doesn't, and how.pdf}
}

@article{Rodriguez.2023,
  title = {Embedding {{Regression}}: {{Models}} for {{Context-Specific Description}} and {{Inference}}},
  shorttitle = {Embedding {{Regression}}},
  author = {Rodriguez, Pedro L. and Spirling, Arthur and Stewart, Brandon M.},
  year = {2023},
  month = nov,
  journal = {American Political Science Review},
  volume = {117},
  number = {4},
  pages = {1255--1274},
  issn = {0003-0554, 1537-5943},
  doi = {10.1017/S0003055422001228},
  url = {https://www.cambridge.org/core/product/identifier/S0003055422001228/type/journal\_article},
  urldate = {2024-04-03},
  abstract = {Social scientists commonly seek to make statements about how word use varies over circumstances---including time, partisan identity, or some other document-level covariate. For example, researchers might wish to know how Republicans and Democrats diverge in their understanding of the term ``immigration.'' Building on the success of pretrained language models, we introduce the {\`a} la carte on text (conText) embedding regression model for this purpose. This fast and simple method produces valid vector representations of how words are used---and thus what words ``mean''---in different contexts. We show that it outperforms slower, more complicated alternatives and works well even with very few documents. The model also allows for hypothesis testing and statements about statistical significance. We demonstrate that it can be used for a broad range of important tasks, including understanding US polarization, historical legislative development, and sentiment detection. We provide open-source software for fitting the model.},
  copyright = {http://creativecommons.org/licenses/by/4.0},
  langid = {english},
  file = {C:\Users\hp\Zotero\storage\VWKVRRXN\Rodriguez et al. - 2023 - Embedding Regression Models for Context-Specific .pdf}
}

@book{Silge.2017,
  title = {Text Mining with {{R}}: A Tidy Approach},
  shorttitle = {Text Mining with {{R}}},
  author = {Silge, Julia and Robinson, David},
  year = {2017},
  edition = {First edition},
  publisher = {O'Reilly},
  address = {Beijing Boston Farnham Sebastopol Tokyo},
  isbn = {978-1-4919-8165-8},
  langid = {english},
  file = {C:\Users\hp\Zotero\storage\HSY353R5\Silge and Robinson - 2017 - Text mining with R a tidy approach.pdf}
}

@book{Silge.a,
  title = {Supervised {{Machine Learning}} for {{Text Analysis}} in {{R}}},
  author = {Silge, Emil Hvitfeldt {and} Julia},
  url = {https://smltar.com/},
  urldate = {2024-09-19},
  abstract = {Supervised Machine Learning for Text Analysis in R},
  file = {C:\Users\hp\Zotero\storage\IU4P4KST\smltar.com.html}
}

@article{Slapin.2008a,
  title = {A {{Scaling Model}} for {{Estimating Time-Series Party Positions}} from {{Texts}}},
  author = {Slapin, Jonathan B. and Proksch, Sven-Oliver},
  year = {2008},
  journal = {American Journal of Political Science},
  volume = {52},
  number = {3},
  pages = {705--722},
  issn = {1540-5907},
  doi = {10.1111/j.1540-5907.2008.00338.x},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1540-5907.2008.00338.x},
  urldate = {2024-05-29},
  abstract = {Recent advances in computational content analysis have provided scholars promising new ways for estimating party positions. However, existing text-based methods face challenges in producing valid and reliable time-series data. This article proposes a scaling algorithm called WORDFISH to estimate policy positions based on word frequencies in texts. The technique allows researchers to locate parties in one or multiple elections. We demonstrate the algorithm by estimating the positions of German political parties from 1990 to 2005 using word frequencies in party manifestos. The extracted positions reflect changes in the party system more accurately than existing time-series estimates. In addition, the method allows researchers to examine which words are important for placing parties on the left and on the right. We find that words with strong political connotations are the best discriminators between parties. Finally, a series of robustness checks demonstrate that the estimated positions are insensitive to distributional assumptions and document selection.},
  copyright = {{\copyright}2008, Midwest Political Science Association},
  langid = {english},
  file = {C\:\\Users\\hp\\Zotero\\storage\\SJ67TCLZ\\Slapin and Proksch - 2008 - A Scaling Model for Estimating Time-Series Party P.pdf;C\:\\Users\\hp\\Zotero\\storage\\CT8QKM4U\\j.1540-5907.2008.00338.html}
}

@article{Stahlberg.2001,
  title = {{Effekte des generischen Maskulinums und alternativer Sprachformen auf den gedanklichen Einbezug von Frauen}},
  author = {Stahlberg, Dagmar and Sczesny, Sabine},
  year = {2001},
  month = jul,
  journal = {Psychologische Rundschau},
  volume = {52},
  number = {3},
  pages = {131--140},
  issn = {0033-3042, 2190-6238},
  doi = {10.1026//0033-3042.52.3.131},
  url = {https://econtent.hogrefe.com/doi/10.1026//0033-3042.52.3.131},
  urldate = {2022-09-15},
  abstract = {Zusammenfassung. In der feministischen Linguistik wird angenommen, da{\ss} maskuline Bezeichnungen, die generisch benutzt werden (Bezeichnungen von Personen beiderlei Geschlechts durch die maskuline Form, wie z.B. die Wissenschaftler, die Studenten), weibliche Personen weniger vorstellbar oder sichtbar machen als m{\"a}nnliche Personen. Verschiedene experimentelle Untersuchungen konnten diese Annahme f{\"u}r den englischen Sprachraum best{\"a}tigen. F{\"u}r die deutsche Sprache existieren dagegen bislang sehr wenige Studien zu dieser Frage. Es werden vier Experimente vorgestellt, die untersuchen, ob unterschiedliche Sprachversionen - ,Beidnennung` (Studentinnen und Studenten), ,Neutral` (Studierende), ,Generisches Maskulinum` (Studenten) und ``Gro{\ss}es I`` (StudentInnen) - den gedanklichen Einbezug von Frauen beeinflussen. {\"U}ber alle Experimente hinweg zeigte sich, da{\ss} bei Personenreferenzen im generischen Maskulinum ein geringerer gedanklicher Einbezug von Frauen zu beobachten war als bei alternativen Sprachformen wie der Beidnennung oder dem ``Gro{\ss}en I`` (z.B. seltenere Nennungen von beliebten weiblichen Pers{\"o}nlichkeiten oder von politischen Kandidatinnen f{\"u}r das Amt des Bundeskanzlers/der Bundeskanzlerin der BRD).},
  langid = {ngerman},
  file = {C:\Users\hp\Zotero\storage\X44HWRJY\Stahlberg and Sczesny - 2001 - Effekte des generischen Maskulinums und alternativ.PDF}
}

@book{Stoltz.2024,
  title = {Mapping {{Texts}}: {{Computational Text Analysis}} for the {{Social Sciences}}},
  shorttitle = {Mapping {{Texts}}},
  author = {Stoltz, Dustin S. and Taylor, Marshall A.},
  year = {2024},
  month = mar,
  edition = {1},
  publisher = {Oxford University PressNew York},
  doi = {10.1093/oso/9780197756874.001.0001},
  url = {https://academic.oup.com/book/55343},
  urldate = {2024-10-04},
  abstract = {Abstract             Mining is the dominant metaphor in computational text analysis. When mining texts, the implied assumption is that analysts can find kernels of truth-they just have to sift through rubbish first. In this book, Stoltz and Taylor encourage text analysts to work with a different metaphor in mind: that of mapping. When mapping texts, the goal is not necessarily to find these meaningful needles in the haystack, but instead to create reductions of the text to document patterns. Just like with cartographic maps, though, the type and nature of the textual map is dependent on a range of decisions on the part of the researcher. Creating reproducible workflows is therefore critical for the text analyst. Mapping Texts offers a practical introduction to computational text analysis with step-by-step guides on how to conduct actual text analysis workflows in the R statistical computing environment. The focus is on social science questions and applications, with data ranging from fake news and presidential campaigns to Star Trek and pop stars. The book walks the reader through all facets of a text analysis workflow-from understanding the theories of language embedded in text analysis all the way to more advanced and cutting-edge techniques. The book should prove useful not only to social scientists, but anyone interested in conducting text analysis projects.},
  isbn = {978-0-19-775687-4 978-0-19-775691-1},
  langid = {english}
}

@article{Stone.1962,
  title = {The General Inquirer: {{A}} Computer System for Content Analysis and Retrieval Based on the Sentence as a Unit of Information},
  shorttitle = {The General Inquirer},
  author = {Stone, Philip J. and Bales, Robert F. and Namenwirth, J. Zvi and Ogilvie, Daniel M.},
  year = {1962},
  journal = {Behavioral Science},
  volume = {7},
  number = {4},
  pages = {484--498},
  issn = {1099-1743},
  doi = {10.1002/bs.3830070412},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/bs.3830070412},
  urldate = {2024-10-07},
  copyright = {Copyright {\copyright} 1962 John Wiley \& Sons, Ltd.},
  langid = {english},
  file = {C\:\\Users\\hp\\OneDrive - Istituto Universitario Europeo\\PhD\\Literature\\Zotero\\Stone et al_1962_The general inquirer2.pdf;C\:\\Users\\hp\\Zotero\\storage\\5K6M5HKG\\bs.html}
}

@article{Stukal.2017,
  title = {Detecting {{Bots}} on {{Russian Political Twitter}}},
  author = {Stukal, Denis and Sanovich, Sergey and Bonneau, Richard and Tucker, Joshua A.},
  year = {2017},
  month = dec,
  journal = {Big Data},
  volume = {5},
  number = {4},
  pages = {310--324},
  publisher = {Mary Ann Liebert, Inc., publishers},
  issn = {2167-6461},
  doi = {10.1089/big.2017.0038},
  url = {https://www.liebertpub.com/doi/abs/10.1089/big.2017.0038},
  urldate = {2024-09-19},
  abstract = {Automated and semiautomated Twitter accounts, bots, have recently gained significant public attention due to their potential interference in the political realm. In this study, we develop a methodology for detecting bots on Twitter using an ensemble of classifiers and apply it to study bot activity within political discussions in the Russian Twittersphere. We focus on the interval from February 2014 to December 2015, an especially consequential period in Russian politics. Among accounts actively Tweeting about Russian politics, we find that on the majority of days, the proportion of Tweets produced by bots exceeds 50\%. We reveal bot characteristics that distinguish them from humans in this corpus, and find that the software platform used for Tweeting is among the best predictors of bots. Finally, we find suggestive evidence that one prominent activity that bots were involved in on Russian political Twitter is the spread of news stories and promotion of media who produce them.}
}

@article{Stukal.2022,
  title = {Why {{Botter}}: {{How Pro-Government Bots Fight Opposition}} in {{Russia}}},
  shorttitle = {Why {{Botter}}},
  author = {Stukal, Denis and Sanovich, Sergey and Bonneau, Richard and Tucker, Joshua A.},
  year = {2022},
  month = aug,
  journal = {American Political Science Review},
  volume = {116},
  number = {3},
  pages = {843--857},
  issn = {0003-0554, 1537-5943},
  doi = {10.1017/S0003055421001507},
  url = {https://www.cambridge.org/core/journals/american-political-science-review/article/why-botter-how-progovernment-bots-fight-opposition-in-russia/D8A8A74976408CF7EC329827AFFFD3FC},
  urldate = {2024-09-19},
  abstract = {There is abundant anecdotal evidence that nondemocratic regimes are harnessing new digital technologies known as social media bots to facilitate policy goals. However, few previous attempts have been made to systematically analyze the use of bots that are aimed at a domestic audience in autocratic regimes. We develop two alternative theoretical frameworks for predicting the use of pro-regime bots: one which focuses on bot deployment in response to offline protest and the other in response to online protest. We then test the empirical implications of these frameworks with an original collection of Twitter data generated by Russian pro-government bots. We find that the online opposition activities produce stronger reactions from bots than offline protests. Our results provide a lower bound on the effects of bots on the Russian Twittersphere and highlight the importance of bot detection for the study of political communication on social media in nondemocratic regimes.},
  langid = {english},
  file = {C:\Users\hp\Zotero\storage\NMKGQMAL\Stukal et al. - 2022 - Why Botter How Pro-Government Bots Fight Oppositi.pdf}
}

@article{Tapper.2023,
  title = {Authors Shocked to Find {{AI}} Ripoffs of Their Books Being Sold on {{Amazon}}},
  author = {Tapper, James},
  year = {2023},
  month = sep,
  journal = {The Guardian},
  issn = {0029-7712},
  url = {https://www.theguardian.com/technology/2023/sep/30/authors-shocked-to-find-ai-ripoffs-of-their-books-being-sold-on-amazon},
  urldate = {2024-10-04},
  abstract = {Book spamming, sometimes with multiple bogus titles going online in one day, has hit writers like Rory Cellan-Jones},
  chapter = {Technology},
  langid = {british},
  keywords = {Amazon,Artificial intelligence (AI),Autobiography and memoir,Books,Computing,E-commerce,Intellectual property,Margaret Atwood,Society of Authors,Technology},
  file = {C:\Users\hp\Zotero\storage\5XY4R4TH\authors-shocked-to-find-ai-ripoffs-of-their-books-being-sold-on-amazon.html}
}

@article{Turing.1950,
  title = {Computing {{Machinery}} and {{Intelligence}}},
  author = {Turing, Alan M.},
  year = {1950},
  month = oct,
  journal = {Mind},
  volume = {LIX},
  number = {236},
  pages = {433--460},
  issn = {0026-4423},
  doi = {10.1093/mind/LIX.236.433},
  url = {https://doi.org/10.1093/mind/LIX.236.433},
  urldate = {2024-10-05},
  file = {C\:\\Users\\hp\\Zotero\\storage\\NRZM7KE4\\TURING - 1950 - I.—COMPUTING MACHINERY AND INTELLIGENCE.pdf;C\:\\Users\\hp\\Zotero\\storage\\CYU42I83\\986238.html}
}

@article{vanLoon.2022,
  title = {Three Families of Automated Text Analysis},
  author = {{van Loon}, Austin},
  year = {2022},
  month = nov,
  journal = {Social Science Research},
  volume = {108},
  pages = {102798},
  issn = {0049-089X},
  doi = {10.1016/j.ssresearch.2022.102798},
  url = {https://www.sciencedirect.com/science/article/pii/S0049089X22001090},
  urldate = {2024-09-05},
  abstract = {Since the beginning of this millennium, data in the form of human-generated text in a machine-readable format has become increasingly available to social scientists, presenting a unique window into social life. However, harnessing vast quantities of this highly unstructured data in a systematic way presents a unique combination of analytical and methodological challenges. Luckily, our understanding of how to overcome these challenges has also developed greatly over this same period. In this article, I present a novel typology of the methods social scientists have used to analyze text data at scale in the interest of testing and developing social theory. I describe three ``families'' of methods: analyses of (1) term frequency, (2) document structure, and (3) semantic similarity. For each family of methods, I discuss their logical and statistical foundations, analytical strengths and weaknesses, as well as prominent variants and applications.},
  keywords = {Automated text analysis,Social science,Text analysis,Text as data},
  file = {C\:\\Users\\hp\\Zotero\\storage\\ENMBDIDW\\van Loon - 2022 - Three families of automated text analysis.pdf;C\:\\Users\\hp\\Zotero\\storage\\J4WTJMGR\\S0049089X22001090.html}
}

@inproceedings{Vaswani.2017,
  title = {Attention Is {{All}} You {{Need}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and ukasz Kaiser, {\L} and Polosukhin, Illia},
  year = {2017},
  volume = {30},
  publisher = {Curran Associates, Inc.},
  url = {https://proceedings.neurips.cc/paper\_files/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html},
  urldate = {2024-06-01},
  abstract = {The dominant sequence transduction models are based on complex recurrent orconvolutional neural networks in an encoder and decoder configuration. The best performing such models also connect the encoder and decoder through an attentionm echanisms.  We propose a novel, simple network architecture based solely onan attention mechanism, dispensing with recurrence and convolutions entirely.Experiments on two machine translation tasks show these models to be superiorin quality while being more parallelizable and requiring significantly less timeto train. Our single model with 165 million parameters, achieves 27.5 BLEU onEnglish-to-German translation, improving over the existing best ensemble result by over 1 BLEU. On English-to-French translation, we outperform the previoussingle state-of-the-art with model by 0.7 BLEU, achieving a BLEU score of 41.1.},
  keywords = {No DOI found},
  file = {C:\Users\hp\Zotero\storage\8CAL55AL\Vaswani et al. - 2017 - Attention is All you Need.pdf}
}

@article{Vervecken.2013,
  title = {Changing ({{S}})Expectations: {{How}} Gender Fair Job Descriptions Impact Children's Perceptions and Interest Regarding Traditionally Male Occupations},
  shorttitle = {Changing ({{S}})Expectations},
  author = {Vervecken, Dries and Hannover, Bettina and Wolter, Ilka},
  year = {2013},
  month = jun,
  journal = {Journal of Vocational Behavior},
  volume = {82},
  number = {3},
  pages = {208--220},
  issn = {00018791},
  doi = {10.1016/j.jvb.2013.01.008},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0001879113000304},
  urldate = {2022-09-15},
  abstract = {Children's occupational interests and their perceptions of the divergent occupational successes of women and men reflect cultural gender norms. Since language is a vehicle for transporting gender cues and gender norms, we tested the premise that children's perceptions of stereotypically male jobs can be influenced by the linguistic form used to present an occupational title. Three experiments with 809 primary school students suggest that occupations presented in pair form (e.g., Ingenieurinnen und Ingenieure, female and male engineers), compared to descriptions using the generic masculine form (e.g., Ingenieure), generally increase the mental accessibility of female jobholders, promote more gender-balanced perceptions of the success of males and females, and strengthen girls' interest in stereotypically male occupations.},
  langid = {english},
  file = {C:\Users\hp\Zotero\storage\RDHAS6SX\Vervecken et al. - 2013 - Changing (S)expectations How gender fair job desc.pdf}
}

@book{VonNeumann.1966,
  title = {Theory of {{Self-Reproducing Automata}}},
  author = {Von Neumann, John and Burks, Arthur W. (Arthur Walter)},
  year = {1966},
  publisher = {Urbana, University of Illinois Press},
  url = {http://archive.org/details/theoryofselfrepr00vonn\_0},
  urldate = {2024-10-05},
  abstract = {Bibliography: p. 297-302},
  collaborator = {{University of Illinois Urbana-Champaign}},
  langid = {english},
  lccn = {510.84 V89t},
  keywords = {Machine theory},
  file = {C:\Users\hp\Zotero\storage\Q5SXS67U\Von Neumann and Burks - 1966 - Theory of Self-Reproducing Automata.pdf}
}

@article{Wankmuller.2022,
  title = {Introduction to {{Neural Transfer Learning With Transformers}} for {{Social Science Text Analysis}}},
  author = {Wankm{\"u}ller, Sandra},
  year = {2022},
  month = dec,
  journal = {Sociological Methods \& Research},
  pages = {1--77},
  issn = {0049-1241, 1552-8294},
  doi = {10.1177/00491241221134527},
  url = {http://journals.sagepub.com/doi/10.1177/00491241221134527},
  urldate = {2024-01-30},
  abstract = {Transformer-based models for transfer learning have the potential to achieve high prediction accuracies on text-based supervised learning tasks with relatively few training data instances. These models are thus likely to benefit social scientists that seek to have as accurate as possible text-based measures, but only have limited resources for annotating training data. To enable social scientists to leverage these potential benefits for their research, this article explains how these methods work, why they might be advantageous, and what their limitations are. Additionally, three Transformer-based models for transfer learning, BERT, RoBERTa, and the Longformer, are compared to conventional machine learning algorithms on three applications. Across all evaluated tasks, textual styles, and training data set sizes, the conventional models are consistently outperformed by transfer learning with Transformers, thereby demonstrating the benefits these models can bring to text-based social science research.},
  langid = {english},
  file = {C:\Users\hp\Zotero\storage\CEQ4BCUD\Wankmüller - 2022 - Introduction to Neural Transfer Learning With Tran.pdf}
}

@article{Wankmuller.2023,
  title = {A Comparison of Approaches for Imbalanced Classification Problems in the Context of Retrieving Relevant Documents for an Analysis},
  author = {Wankm{\"u}ller, Sandra},
  year = {2023},
  journal = {Journal of Computational Social Science},
  volume = {6},
  number = {1},
  pages = {91--163},
  publisher = {Springer},
  issn = {2432-2725},
  doi = {10.1007/s42001-022-00191-7},
  url = {https://econpapers.repec.org/article/sprjcsosc/v\_3a6\_3ay\_3a2023\_3ai\_3a1\_3ad\_3a10.1007\_5fs42001-022-00191-7.htm},
  urldate = {2024-06-02},
  abstract = {Abstract One of the first steps in many text-based social science studies is to retrieve documents that are relevant for an analysis from large corpora of otherwise irrelevant documents. The conventional approach in social science to address this retrieval task is to apply a set of keywords and to consider those documents to be relevant that contain at least one of the keywords. But the application of incomplete keyword lists has a high risk of drawing biased inferences. More complex and costly methods such as query expansion techniques, topic model-based classification rules, and active as well as passive supervised learning could have the potential to more accurately separate relevant from irrelevant documents and thereby reduce the potential size of bias. Yet, whether applying these more expensive approaches increases retrieval performance compared to keyword lists at all, and if so, by how much, is unclear as a comparison of these approaches is lacking. This study closes this gap by comparing these methods across three retrieval tasks associated with a data set of German tweets (Linder in SSRN, 2017. https://doi.org/10.2139/ssrn.3026393 ), the Social Bias Inference Corpus (SBIC) (Sap et al. in Social bias frames: reasoning about social and power implications of language. In: Jurafsky et al. (eds) Proceedings of the 58th annual meeting of the association for computational linguistics. Association for Computational Linguistics, p 5477--5490, 2020. https://doi.org/10.18653/v1/2020.aclmain.486 ), and the Reuters-21578 corpus (Lewis in Reuters-21578 (Distribution 1.0). [Data set], 1997. http://www.daviddlewis.com/resources/testcollections/reuters21578/ ). Results show that query expansion techniques and topic model-based classification rules in most studied settings tend to decrease rather than increase retrieval performance. Active supervised learning, however, if applied on a not too small set of labeled training instances (e.g. 1000 documents), reaches a substantially higher retrieval performance than keyword lists.},
  keywords = {Active learning,Boolean query,Imbalanced classification,Keyword lists,Query expansion,Topic models},
  file = {C:\Users\hp\Zotero\storage\9L9DIRCD\v_3a6_3ay_3a2023_3ai_3a1_3ad_3a10.1007_5fs42001-022-00191-7.html}
}

@article{Watanabe.2021,
  title = {Latent {{Semantic Scaling}}: {{A Semisupervised Text Analysis Technique}} for {{New Domains}} and {{Languages}}},
  author = {Watanabe, Kohei},
  year = {2021},
  month = jan,
  journal = {Communication Methods and Measures},
  volume = {15},
  number = {2},
  pages = {81--102},
  issn = {1931-2458},
  doi = {10.1080/19312458.2020.1832976}
}

@book{Wickham.2023,
  title = {R for {{Data Science}}},
  author = {Wickham, Hadley and {\c C}etinkaya-Rundel, Mine and Grolemund, Garrett},
  year = {2023},
  month = jun,
  publisher = {O'Reilly Media, Inc.},
  url = {https://r4ds.hadley.nz/},
  abstract = {Use R to turn data into insight, knowledge, and understanding. With this practical book, aspiring data scientists will learn how to do data science with R and RStudio, along with the tidyverse---a collection of R packages designed to work together to make data science fast, fluent, and fun. Even if you have no programming experience, this updated edition will have you doing data science quickly.You'll learn how to import, transform, and visualize your data and communicate the results. And you'll get a complete, big-picture understanding of the data science cycle and the basic tools you need to manage the details. Updated for the latest tidyverse features and best practices, new chapters show you how to get data from spreadsheets, databases, and websites. Exercises help you practice what you've learned along the way.You'll understand how to:Visualize: Create plots for data exploration and communication of resultsTransform: Discover variable types and the tools to work with themImport: Get data into R and in a form convenient for analysisProgram: Learn R tools for solving data problems with greater clarity and easeCommunicate: Integrate prose, code, and results with Quarto},
  googlebooks = {TiLEEAAAQBAJ},
  isbn = {978-1-4920-9736-5},
  langid = {english},
  keywords = {Computers / Data Science / Data Analytics,Computers / Data Science / Data Modeling & Design,Computers / Data Science / Data Visualization,Computers / Data Science / General,Computers / Data Science / Machine Learning,Computers / Mathematical & Statistical Software,Mathematics / Probability & Statistics / General}
}

@article{Zollinger.2024,
  title = {Cleavage {{Identities}} in {{Voters}}' {{Own Words}}: {{Harnessing Open-Ended Survey Responses}}},
  shorttitle = {Cleavage {{Identities}} in {{Voters}}' {{Own Words}}},
  author = {Zollinger, Delia},
  year = {2024},
  journal = {American Journal of Political Science},
  volume = {68},
  number = {1},
  pages = {139--159},
  issn = {1540-5907},
  doi = {10.1111/ajps.12743},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/ajps.12743},
  urldate = {2024-04-30},
  abstract = {Fundamental transformations of underlying cleavage structures in advanced democracies should become evident in new collective identities. This article uses quantitative text analysis to investigate how voters describe their ingroups and outgroups in open-ended survey responses. I look at Switzerland, a paradigmatic case of electoral realignment along a ``second,'' universalism--particularism dimension of politics opposing the far right and the new left. Keyness statistics and a semi-supervised document scaling method (latent semantic scaling) serve to identify terms associated with the poles of this divide in voters' responses, and hence to measure universalist/particularist identities. Based on voters' own words, the results support the idea of collective identities consolidating an emerging cleavage: Voters' identity descriptions relate to far right versus new left support, along with known sociostructural and attitudinal correlates of the universalism--particularism divide, and they reveal how groups opposed on this dimension antagonistically demarcate themselves from each other.},
  copyright = {{\copyright} 2022 The Authors. American Journal of Political Science published by Wiley Periodicals LLC on behalf of Midwest Political Science Association.},
  langid = {english},
  file = {C\:\\Users\\hp\\Zotero\\storage\\QVUL5DWW\\Zollinger - 2024 - Cleavage Identities in Voters’ Own Words Harnessi.pdf;C\:\\Users\\hp\\Zotero\\storage\\CCH96X2F\\ajps.html}
}
